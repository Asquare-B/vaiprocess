{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxJMgWLs4oxN"
      },
      "outputs": [],
      "source": [
        "#@title 1hist\n",
        "#matplotlib\n",
        "plt.hist(img.ravel(), 256, [0, 256])\n",
        "#256 - max number of pixel\n",
        "#0-255 - range of the pixel\n",
        "plt.show()\n",
        "\n",
        "# 2) How to add white pixel to the image\n",
        "\"\"\"import numpy as np\n",
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "img = np.zeros((200, 200), np.uint8)\n",
        "cv.rectangle(img, (0,100), (200,200), (255), -1)\n",
        "#(0,100), (200,200) are the demension of image\n",
        "# 255 pixel value for the created rectangle\n",
        "#-1 thickness to fill the rectangle\n",
        "#cv.imshow(\"img\", img)\n",
        "plt.hist(img.ravel(), 256, [0,256])\n",
        "plt.show()\"\"\"\n",
        "# let us add some more pixels to the image\n",
        "\"\"\"import numpy as np\n",
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "img = np.zeros((200, 200), np.uint8)\n",
        "cv.rectangle(img, (0,100), (200,200), (255), -1)\n",
        "cv.rectangle(img, (0,50), (100,100), (127), -1)\n",
        "#15000 pixels are black, 20000 pixels are white and 5000 pixels are gray\n",
        "plt.hist(img.ravel(), 256, [0,256])\n",
        "plt.show()\"\"\"\n",
        "\n",
        "\n",
        "#let us try to use image for hist\n",
        "\"\"\"import numpy as np\n",
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "img = cv.imread('grey.tif', 1)\n",
        "plt.hist(img.ravel(), 256, [0,256])\n",
        "#plt.imshow(img)\n",
        "plt.show()\"\"\"\n",
        "\n",
        "#How to find the pixel intensity of different colors. \n",
        "\"\"\"import numpy as np\n",
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "img = cv.imread('Colorimage.jpg', 1)\n",
        "b,g,r=cv.split(img)\n",
        "cv.imshow(\"img\", img)\n",
        "cv.imshow(\"img\", b)\n",
        "cv.imshow(\"img\", g)\n",
        "cv.imshow(\"img\", r)\n",
        "plt.hist(b.ravel(), 256, [0,256])\n",
        "plt.hist(g.ravel(), 256, [0,256])\n",
        "plt.hist(r.ravel(), 256, [0,256])\n",
        "plt.show()\"\"\"\n",
        "\n",
        "\n",
        "#Histogram plot using cv2\\\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt \n",
        "img = cv.imread('grey.tif')\n",
        "hist = cv.calcHist([img], [0], None, [10], [0,256])\n",
        "plt.plot(hist)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Affine transform\n",
        "img =cv2.imread('Colorimage.jpg')\n",
        "rows, columns, ch = img.shape  #function shape returns the shape of the i/p image\n",
        "pt1 = np.float32([[50,50], [200,50], [50, 200]])\n",
        "#pt(point) is defined in the original image, this point should not be co-linear\n",
        "pt2 = np.float32([[10,100], [200,50], [100, 250]])\n",
        "matrix = cv2.getAffineTransform(pt1, pt2) #Transform function to create a matrix\n",
        "new_img = cv2.warpAffine(img, matrix, (columns, rows))"
      ],
      "metadata": {
        "id": "u2qFM1N_65JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title distance\n",
        "\n",
        "image = np.zeros((36,36,3), np.uint8)\n",
        "\n",
        "#selection of red pixel location\n",
        "image[10,15] = [255,0,0] # 0 - B, 0 -G, 255 - Red\n",
        "\n",
        "#Choose green pixel location\n",
        "\n",
        "image[21,23] = [0, 255, 0]\n",
        "\n",
        "cv2.imwrite('created_image.jpeg', image)\n",
        "plt.imshow(image) \n",
        "\n",
        "#To find the distance between the pixels\n",
        "x1, y1, x2, y2 = 10, 15, 21, 23\n",
        "distance = math.sqrt((x2-x1)**2 -(y2-y1)**2)\n",
        "print(distance)"
      ],
      "metadata": {
        "id": "GnIPbW8V7JaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title filter all\n",
        "\n",
        "img = cv2.imread('salt_pepper.png')\n",
        "#img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # converting image from BGR to RGB\n",
        "\n",
        "#opencv read the image in BGR format\n",
        "\n",
        "#define the kernel with 5 by 5\n",
        "kernel=np.ones((5,5), np.float32)/25\n",
        "\n",
        "out_img=cv2.filter2D(img, -1, kernel)\n",
        "blur=cv2.blur(img, (5,5))\n",
        "\n",
        "gblur=cv2.GaussianBlur(img, (5,5), 0)\n",
        "\n",
        "median =cv2.medianBlur(img, 5)\n",
        "\n",
        "bilateralfilter = cv2.bilateralFilter(img, 9, 75, 75)\n",
        "#img - input image\n",
        "#-1 desired depth of output image\n",
        "#Apply kernel on the image using filter 2D\n",
        "\"\"\"titles = ['image', '2Dconvolution']\n",
        "images=[img, out_img]\"\"\" \n",
        "\n",
        "\n",
        "titles = ['image', '2Dconvolution', 'blur', 'gblur', 'median', 'bilateralfilter']\n",
        "images=[img, out_img, blur, gblur, median, bilateralfilter] \n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2, 3, i+1), plt.imshow(images[i], 'gray')\n",
        "    plt.title(titles[i])\n",
        "    plt.xticks([]), plt.yticks([])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZbjLMBB87U28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title gamma transform\n",
        "img = cv2.imread('grey.tif', 1) # 0 reads as a grey scale image\n",
        "gamma = 2   # gamma transform\n",
        "img_gamma1 = np.power(img, gamma)  #raising the image by gamma(2) \n",
        "\n",
        "gamma = 10\n",
        "img_gamma2 = np.power(img, gamma) \n",
        "\n",
        "\n",
        "gamma = 20\n",
        "img_gamma3 = np.power(img, gamma) \n",
        "\n",
        "plt.subplot(221), plt.imshow(img), plt.title('input image')\n",
        "plt.subplot(222), plt.imshow(img_gamma1), plt.title('gamma=2')\n",
        "plt.subplot(223), plt.imshow(img_gamma2), plt.title('gamma=10')\n",
        "plt.subplot(224), plt.imshow(img_gamma3), plt.title('gamma=20')"
      ],
      "metadata": {
        "id": "ZWJ-0WPe7aX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title histogram equ\n",
        "\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "img =cv2.imread('Colorimage.jpg')\n",
        "\n",
        "#converting image to LAB color\n",
        "lab_image=cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "l, a, b =cv2.split(lab_image)\n",
        "\n",
        "#histogram of l component\n",
        "plt.hist(l.flat, bins=100, range=(0,255))\n",
        "plt.show()\n",
        "\n",
        "#Apply histogram equalization on L channel\n",
        "equ = cv2.equalizeHist(l)\n",
        "plt.hist(equ.flat, bins=100, range=(0,255))\n",
        "plt.show()\n",
        "\n",
        "#combine the hist equalized l channel back to A and B channel\n",
        "updated_lab_img1 = cv2.merge((equ, a, b))\n",
        "\n",
        "#Convert the LAB image back to color(RGB)\n",
        "hist_eq_image =cv2.cvtColor(updated_lab_img1, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "\n",
        "#Apply CLAHE to L channel\n",
        "clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
        "clahe_img = clahe.apply(l)\n",
        "\n",
        "#PLot the histogram\n",
        "plt.hist(clahe_img.flat, bins=100, range=(10, 255))\n",
        "\n",
        "#combine the CLAHE enhanced L-channel back to A and B\n",
        "updated_lab_img2 = cv2.merge((clahe_img, a, b))\n",
        "\n",
        "#Convert the LAB image back to color(RGB)\n",
        "\n",
        "CLAHE_img = cv2.cvtColor(updated_lab_img2, cv2.COLOR_LAB2RGB)\n",
        "\"\"\"plt.show('original image', img)\n",
        "plt.show('equalized image', hist_eq_image)\n",
        "plt.show('CLAHE IMAGE', CLAHE_img)\"\"\"\n",
        "\n",
        "\n",
        "cv2.imshow('original image', img)\n",
        "cv2.imshow('equalized image', hist_eq_image)\n",
        "cv2.imshow('CLAHE IMAGE', CLAHE_img)\n",
        "cv2.waitKey(0)"
      ],
      "metadata": {
        "id": "movVmmaP7lPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title inverse log\n",
        "\n",
        "\"\"\"from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.colors import NoNorm\n",
        "r = np.arange(0, 255)\n",
        "c=255/(np.log(1+255))\n",
        "y=np.exp(r)**(1/c)-1\n",
        "plt.plot(r,y)\"\"\"\n",
        "\n",
        "#Apply Inverse log transform on image\n",
        "\n",
        "from skimage import io\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.colors import NoNorm\n",
        "img = io.imread('lighterimage.tif')\n",
        "c=255/np.log(1+255)\n",
        "inverse_log_image = np.exp(img**1/c)-1\n",
        "inverse_log_image = np.array(inverse_log_image, dtype=np.uint8) #float is converted to int8\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(img, cmap='gray', norm=NoNorm())\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(inverse_log_image, cmap='gray', norm=NoNorm())\n",
        "#plt.imshow(log_image, cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Dub-CyxH7vyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title open close dilate\n",
        "img = cv2.imread('morpho.tif', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "_, mask =cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "# 127 - VALUE OF THRESHOLD\n",
        "\n",
        "kernel = np.ones((5,5), np.uint8)\n",
        "#dilation =cv2.dilate(mask, kernel)\n",
        "dilation =cv2.dilate(mask, kernel, iterations=1)\n",
        "#In the dilation process black pixel were reduced, or white pixel are incresed.\n",
        "\n",
        "# To remove the black pixel completely, i apply iteration, apply kernel for any number of iteration.\n",
        "\n",
        "#bigger the kernel size, black pixel are turned to white, by dilation but size of the white object is increased   \n",
        "\n",
        "#Dilation -  if atleast one pixel matches with kernel, than change the pixel to 1\n",
        "\n",
        "#Therefore the shape of white object is increasing. \n",
        "\n",
        "erosion = cv2.erode(mask, kernel, iterations=1)\n",
        "\n",
        "# the shape of the white object is reduced.  erosion - all pixels of image need to be match with kernel, than 1 else 0. \n",
        "\n",
        "\n",
        "opening = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "#erosion followed by dilation\n",
        "closing = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "#dilation followed by erosion\n",
        "\n",
        "#change the kernel size and iteration number and see the difference.\n",
        "\n",
        "gradient = cv2.morphologyEx(mask, cv2.MORPH_GRADIENT, kernel)\n",
        "#difference between the dilation and erosion\n",
        "\n",
        "tophat=cv2.morphologyEx(mask, cv2.MORPH_TOPHAT, kernel)\n",
        "\n",
        "#diff b/w the input image and opening image.\n",
        "\n",
        "titles = ['input image', 'mask', 'dilation', 'erosion', 'opening', 'gradient', 'tophat']\n",
        "images = [img, mask, dilation, erosion, opening, gradient, tophat]"
      ],
      "metadata": {
        "id": "XwZflWTf8Ahm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title tranform\n",
        "img_vh=cv2.flip(img, -1) #refleection\n",
        "\n",
        "#rotation\n",
        "img=cv2.imread('grey.tif', 0)\n",
        "plt.imshow(img)\n",
        "rows, cols = img.shape  \n",
        "\n",
        "matrix = cv2.getRotationMatrix2D((rows/2, cols/2), 60, 1)\n",
        "#matrix =cv2.getRotationMatrix2D((rows/2, cols/2), 60, 2.5)\n",
        "new_img = cv2.warpAffine(img, matrix, (500, 320))\n",
        "new_img = cv2.warpAffine(img, matrix, (rows, cols))\n",
        "\n",
        "#translation\n",
        "img = cv2.imread('color.jpg')\n",
        "plt.imshow(img)\n",
        "\n",
        "height, width = img.shape[:2]\n",
        "print(height, width)\n",
        "\n",
        "height_fourth, width_fourth = height/4, width/4\n",
        "\n",
        "print(height_fourth, width_fourth)\n",
        "\n",
        "#Translate matrix\n",
        "t = np.float32([[1,0,height_fourth], [0,1, width_fourth]])\n",
        "\n",
        "print(t)\n",
        "translation=cv2.warpAffine(img, t, (width, height))\n",
        "plt.imshow(translation)"
      ],
      "metadata": {
        "id": "K56Lro-E8LkF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}