{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title hough tranform\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "img = cv2.imread('line_hough.jpg')\n",
        "\n",
        "sob_8u = cv2.Sobel(img,cv2.CV_8U,1,0,ksize=3)\n",
        "\n",
        "sobel_64 = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)\n",
        "abs_64 = np.absolute(sobel_64)\n",
        "sobel_8u = np.uint8(abs_64)\n",
        "\n",
        "cv2.imshow('a1',sobel_8u)\n",
        "cv2.waitKey(0)\n",
        "\n",
        "img = sobel_8u\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "th = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "sk = cv2.ximgproc.thinning(th, None, 1)  \n",
        "\n",
        "k1 = np.array(([0, 0, 0], [-1, 1, -1], [-1, -1, -1]), dtype=\"int\")\n",
        "k2 = np.array(([0, -1, -1], [0, 1, -1], [0, -1, -1]), dtype=\"int\")\n",
        "k3 = np.array(([-1, -1, 0],  [-1, 1, 0], [-1, -1, 0]), dtype=\"int\")\n",
        "k4 = np.array(([-1, -1, -1], [-1, 1, -1], [0, 0, 0]), dtype=\"int\")\n",
        "\n",
        "k5 = np.array(([-1, -1, -1], [-1, 1, -1], [0, -1, -1]), dtype=\"int\")\n",
        "k6 = np.array(([-1, -1, -1], [-1, 1, -1], [-1, -1, 0]), dtype=\"int\")\n",
        "k7 = np.array(([-1, -1, 0], [-1, 1, -1], [-1, -1, -1]), dtype=\"int\")\n",
        "k8 = np.array(([0, -1, -1], [-1, 1, -1], [-1, -1, -1]), dtype=\"int\")               \n",
        "\n",
        "o1 = cv2.morphologyEx(sk, cv2.MORPH_HITMISS, k1)\n",
        "o2 = cv2.morphologyEx(sk, cv2.MORPH_HITMISS, k2)\n",
        "o3 = cv2.morphologyEx(sk, cv2.MORPH_HITMISS, k3)\n",
        "o4 = cv2.morphologyEx(sk, cv2.MORPH_HITMISS, k4)\n",
        "out1 = o1 + o2 + o3 + o4\n",
        "\n",
        "o5 = cv2.morphologyEx(sk, cv2.MORPH_HITMISS, k5)\n",
        "o6 = cv2.morphologyEx(sk, cv2.MORPH_HITMISS, k6)\n",
        "o7 = cv2.morphologyEx(sk, cv2.MORPH_HITMISS, k7)\n",
        "o8 = cv2.morphologyEx(sk, cv2.MORPH_HITMISS, k8)\n",
        "out2 = o5 + o6 + o7 + o8\n",
        "\n",
        "out = cv2.add(out1, out2)\n",
        "pts = np.argwhere(out == 255)\n",
        "loose_ends = img.copy()\n",
        "for pt in pts:\n",
        "    loose_ends = cv2.circle(loose_ends, (pt[1], pt[0]), 3, (0,255,0), -1)\n",
        "pts = list(map(tuple, pts))\n",
        "final = img.copy()\n",
        "\n",
        "for i, pt1 in enumerate(pts):\n",
        "  min_dist = max(img.shape[:2])\n",
        "  sub_pts = pts.copy()\n",
        "  del sub_pts[i]\n",
        "  pt_2 = None\n",
        "  for pt2 in sub_pts:\n",
        "    dist = int(np.linalg.norm(np.array(pt1) - np.array(pt2)))\n",
        "    if dist < min_dist:\n",
        "      min_dist = dist   \n",
        "      pt_2 = pt2\n",
        "  final = cv2.line(final, (pt1[1], pt1[0]), (pt_2[1], pt_2[0]), (0, 0, 255), thickness = 2)\n",
        "\n",
        "cv2.imshow('Final Image',final)\n",
        "cv2.waitKey(0)\n"
      ],
      "metadata": {
        "id": "kd96YRw79mUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title K means algo\n",
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "img = cv2.imread(\"seg3.tif\")\n",
        "\n",
        "img2 = img.reshape((-1,3))\n",
        "\n",
        "img2 = np.float32(img2)\n",
        "\n",
        "\n",
        "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "\n",
        "k = 3\n",
        "\n",
        "attempts = 3\n",
        "\n",
        "\n",
        "ret,label,center=cv2.kmeans(img2, k, None, criteria, attempts, cv2.KMEANS_PP_CENTERS)\n",
        "\n",
        "center = np.uint8(center) \n",
        "\n",
        "res = center[label.flatten()]   \n",
        "res2 = res.reshape((img.shape)) \n",
        "cv2.imwrite(\"segmented.jpg\", res2)\n",
        "\n",
        "\n",
        "titles = ['original image', 'segmentation image']\n",
        "images = [img, res2]\n",
        "\n",
        "for i in range(2):\n",
        "    plt.subplot(1, 2, i+1), plt.imshow(images[i], 'gray')\n",
        "    plt.title(titles[i])\n",
        "    plt.xticks([]), plt.yticks([])\n",
        "    \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0H-zeI1blyxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Segmentation color\n",
        "\n",
        "from skimage import io, measure\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from scipy import ndimage as nd\n",
        "from skimage import img_as_ubyte\n",
        "\n",
        "img = io.imread('color.png')\n",
        "plt.imshow(img)\n",
        "\n",
        "#In the input image, we have bunch of colors, we segment image on pixel based on the specific color\n",
        "hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "#hsv demension is same as input image\n",
        "\n",
        "mask = cv2.inRange(hsv, (100, 90, 90), (120, 255, 255))\n",
        "#at center dark blue, at edge -light blue H is 100 to 120\n",
        "#sat - 90 to 255 and V is from 90 to 2355\n",
        "#mask =cv2.inRange(hsv, (0,0,100), (180, 70, 255)) for white color\n",
        "\n",
        "plt.imshow(mask)\n",
        "\n",
        "#in the output i have some holes - to close it i use binary closing operation\n",
        "#(dilation followed by erosion)\n",
        "closed_mask = nd.binary_closing(mask, np.ones((5,5)))\n",
        "plt.imshow(closed_mask)\n",
        "\n",
        "#after segmentation each object given a unique label value\n",
        "label_image = measure.label(closed_mask)\n",
        "plt.imshow(label_image)\n",
        "\n",
        "\n",
        "from skimage.color import label2rgb\n",
        "image_label_overlay = label2rgb(label_image, image=img)\n",
        "#it takes the original image and overlay the label image on top of that in RGB\n",
        "#in the input image the blue balls are in different color and all other colors of ball are black and white\n",
        "\n",
        "plt.imshow(image_label_overlay)\n",
        "img_as_8byte = img_as_ubyte(image_label_overlay)\n",
        "\n",
        "#To calculate image properties (area, centroid, convex_area, label, intensity image, major axis length and so on)\n",
        "#import this data as pandas-compatible table.\n",
        "\n",
        "props = measure.regionprops_table(img_as_8byte, img, properties=['label', 'area'])\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(props)\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YRPOXGvpl_oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Watershed algo\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage import color\n",
        "\n",
        "img1 = cv2.imread(\"watershed.jpg\")\n",
        "img = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "#Threshold image to binary using OTSU. ALl thresholded pixels will be set to 255\n",
        "ret1, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "\n",
        "cv2.imshow('Threshold', thresh)\n",
        "cv2.waitKey(0)\n",
        "\n",
        "print(ret1)\n",
        "\n",
        "# Morphological operations to remove small noise - opening\n",
        "#To remove holes we can use closing\n",
        "kernel = np.ones((3,3),np.uint8)\n",
        "opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 1)\n",
        "\n",
        "cv2.imshow('opening', opening)\n",
        "cv2.waitKey(0)\n",
        "\n",
        "\n",
        "from skimage.segmentation import clear_border\n",
        "opening = clear_border(opening) #Remove edge touching objects\n",
        " \n",
        "cv2.imshow('opening', opening)\n",
        "cv2.waitKey(0)\n",
        "\n",
        "# finding sure background by dilation\n",
        "sure_bg = cv2.dilate(opening,kernel,iterations=2)\n",
        "\n",
        "cv2.imshow('sure_bg', sure_bg)\n",
        "cv2.waitKey(0)\n",
        "\n",
        "# Finding sure foreground area using distance transform and thresholding\n",
        "dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,3) \n",
        "\n",
        "cv2.imshow('dist_transform', dist_transform)\n",
        "cv2.waitKey(0)\n",
        "\n",
        "\n",
        "print(dist_transform.max()) #gives about 38.200073\n",
        "ret2, sure_fg = cv2.threshold(dist_transform,0.001*dist_transform.max(),255,0)\n",
        "\n",
        "cv2.imshow('sure_fg', sure_fg)\n",
        "cv2.waitKey(0)\n",
        "\n",
        "# Unknown ambiguous region is nothing but bkground - foreground\n",
        "sure_fg = np.uint8(sure_fg)\n",
        "\n",
        "unknown = cv2.subtract(sure_bg,sure_fg)\n",
        "\n",
        "cv2.imshow('unknow', unknown)\n",
        "cv2.waitKey(0)\n",
        "\n",
        "\n",
        "#Now we create a marker and label the regions inside. \n",
        "# For sure regions, both foreground and background will be labeled with positive numbers.\n",
        "# Unknown regions will be labeled 0. \n",
        "ret3, markers = cv2.connectedComponents(sure_fg)\n",
        "\n",
        "#So let us add 10 to all labels so that sure background is not 0, but 10\n",
        "markers = markers+10\n",
        "\n",
        "# Now, mark the region of unknown with zero\n",
        "markers[unknown==255] = 0   #if my unknow is 255 then my marker is 0\n",
        "plt.imshow(markers, cmap='jet')\n",
        "\n",
        "#Now we are ready for watershed filling. \n",
        "markers = cv2.watershed(img1,markers)\n",
        "\n",
        "#boundaries to -1 after watershed.\n",
        "img1[markers == -1] = [255,0,255]  \n",
        "\n",
        "img2 = color.label2rgb(markers, bg_label=0)\n",
        "\n",
        "cv2.imshow('Overlay on original image', img1)\n",
        "cv2.imshow('Colored', img2)\n",
        "cv2.waitKey(0)\n"
      ],
      "metadata": {
        "id": "dPYqA0BkpFGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title image Segmentation SEGHE\n",
        "\n",
        "from skimage import io\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "img = io.imread(\"noise.png\",0)\n",
        "\n",
        "\n",
        "from skimage.restoration import denoise_nl_means, estimate_sigma\n",
        "from skimage import img_as_ubyte, img_as_float\n",
        "\n",
        "\n",
        "float_img = img_as_float(img)\n",
        "sigma_est = np.mean(estimate_sigma(float_img, multichannel=True))\n",
        "\n",
        "\n",
        "denoise_img = denoise_nl_means(float_img, h=15 * sigma_est, fast_mode=False, \n",
        "                               patch_size=5, patch_distance=3, multichannel=True)\n",
        "                           \n",
        "denoise_img_as_8byte = img_as_ubyte(denoise_img)\n",
        "\n",
        "segm1 = (denoise_img_as_8byte <= 25)\n",
        "segm2 = (denoise_img_as_8byte > 25) & (denoise_img_as_8byte <= 75)\n",
        "segm3 = (denoise_img_as_8byte > 75) & (denoise_img_as_8byte <= 125)\n",
        "segm4 = (denoise_img_as_8byte > 125)\n",
        "\n",
        "\n",
        "all_segments = np.zeros((denoise_img_as_8byte.shape[0], denoise_img_as_8byte.shape[1], 3)) #nothing but denoise img size but blank\n",
        "\n",
        "\n",
        "all_segments[segm1] = (1,0,0)\n",
        "all_segments[segm2] = (0,1,0)\n",
        "all_segments[segm3] = (0,0,1)\n",
        "all_segments[segm4] = (1,1,0)\n",
        "plt.imshow(all_segments)\n",
        "\n",
        "\n",
        "from scipy import ndimage as nd\n",
        "\n",
        "segm1_opened = nd.binary_opening(segm1, np.ones((3,3)))\n",
        "segm1_closed = nd.binary_closing(segm1_opened, np.ones((3,3)))\n",
        "\n",
        "segm2_opened = nd.binary_opening(segm2, np.ones((3,3)))\n",
        "segm2_closed = nd.binary_closing(segm2_opened, np.ones((3,3)))\n",
        "\n",
        "segm3_opened = nd.binary_opening(segm3, np.ones((3,3)))\n",
        "segm3_closed = nd.binary_closing(segm3_opened, np.ones((3,3)))\n",
        "\n",
        "segm4_opened = nd.binary_opening(segm4, np.ones((3,3)))\n",
        "segm4_closed = nd.binary_closing(segm4_opened, np.ones((3,3)))\n",
        "\n",
        "all_segments_cleaned = np.zeros((denoise_img_as_8byte.shape[0], denoise_img_as_8byte.shape[1], 3)) #nothing but 300, 300, 3\n",
        "\n",
        "all_segments_cleaned[segm1_closed] = (0,0,1)\n",
        "all_segments_cleaned[segm2_closed] = (0,1,0)\n",
        "all_segments_cleaned[segm3_closed] = (1,0,0)\n",
        "all_segments_cleaned[segm4_closed] = (1,1,0)\n",
        "\n",
        "plt.imshow(all_segments_cleaned)  "
      ],
      "metadata": {
        "id": "3E2jb16Bp0H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title fft\n",
        "\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = np.arange(256)  \n",
        "y = np.sin(2 * np.pi * x / 4) \n",
        "y += max(y) \n",
        "img = np.array([[y[j]*127 for j in range(256)] for i in range(256)], dtype=np.uint8) # create 2-D array of sine-wave\n",
        "\n",
        "plt.imshow(img)\n",
        "\n",
        "img = cv2.imread('color.png', 0) # load an image\n",
        "\n",
        "dft = cv2.dft(np.float32(img), flags=cv2.DFT_COMPLEX_OUTPUT)\n",
        "\n",
        "dft_shift = np.fft.fftshift(dft)\n",
        "\n",
        "magnitude_spectrum = 20 * np.log((cv2.magnitude(dft_shift[:, :, 0], dft_shift[:, :, 1]))+1)\n",
        "fig = plt.figure(figsize=(12, 12))\n",
        "ax1 = fig.add_subplot(2,2,1)\n",
        "ax1.imshow(img)\n",
        "ax1.title.set_text('Input Image')\n",
        "ax2 = fig.add_subplot(2,2,2)\n",
        "ax2.imshow(magnitude_spectrum)\n",
        "ax2.title.set_text('FFT of image')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ya8cTrgtruon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title image ft\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "img = cv2.imread('color.png', 0)\n",
        "dft = cv2.dft(np.float32(img), flags=cv2.DFT_COMPLEX_OUTPUT)\n",
        "dft_shift = np.fft.fftshift(dft)\n",
        "magnitude_spectrum = 20 * np.log(cv2.magnitude(dft_shift[:, :, 0], dft_shift[:, :, 1]))\n",
        "\n",
        "rows, cols = img.shape\n",
        "crow, ccol = int(rows / 2), int(cols / 2)\n",
        "mask = np.ones((rows, cols, 2), np.uint8)\n",
        "r = 50 \n",
        "center = [crow, ccol]\n",
        "x, y = np.ogrid[:rows, :cols]\n",
        "mask_area = (x - center[0]) ** 2 + (y - center[1]) ** 2 <= r*r\n",
        "mask[mask_area] = 0\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "rows, cols = img.shape\n",
        "crow, ccol = int(rows / 2), int(cols / 2)\n",
        "mask = np.zeros((rows, cols, 2), np.uint8)\n",
        "r = 200\n",
        "center = [crow, ccol]\n",
        "x, y = np.ogrid[:rows, :cols]\n",
        "mask_area = (x - center[0]) ** 2 + (y - center[1]) ** 2 <= r*r\n",
        "mask[mask_area] = 1\n",
        "\"\"\"\n",
        "# Band Pass Filter - Concentric circle mask, only the points living in concentric circle are ones\n",
        "\"\"\"rows, cols = img.shape\n",
        "crow, ccol = int(rows / 2), int(cols / 2)\n",
        "mask = np.zeros((rows, cols, 2), np.uint8)\n",
        "r_out = 80\n",
        "r_in = 10\n",
        "center = [crow, ccol]\n",
        "x, y = np.ogrid[:rows, :cols]\n",
        "mask_area = np.logical_and(((x - center[0]) ** 2 + (y - center[1]) ** 2 >= r_in ** 2),\n",
        "                           ((x - center[0]) ** 2 + (y - center[1]) ** 2 <= r_out ** 2))\n",
        "mask[mask_area] = 1\"\"\"\n",
        "\n",
        "\n",
        "fshift = dft_shift * mask\n",
        "\n",
        "fshift_mask_mag = 20 * np.log(cv2.magnitude(fshift[:, :, 0], fshift[:, :, 1]))\n",
        "\n",
        "\n",
        "f_ishift = np.fft.ifftshift(fshift)\n",
        "\n",
        "img_back = cv2.idft(f_ishift)\n",
        "\n",
        "img_back = cv2.magnitude(img_back[:, :, 0], img_back[:, :, 1])\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(12, 12))\n",
        "ax1 = fig.add_subplot(2,2,1)\n",
        "ax1.imshow(img, cmap='gray')\n",
        "ax1.title.set_text('Input Image')\n",
        "ax2 = fig.add_subplot(2,2,2)\n",
        "ax2.imshow(magnitude_spectrum, cmap='gray')\n",
        "ax2.title.set_text('FFT of image')\n",
        "ax3 = fig.add_subplot(2,2,3)\n",
        "ax3.imshow(fshift_mask_mag, cmap='gray')\n",
        "ax3.title.set_text('FFT + Mask')\n",
        "ax4 = fig.add_subplot(2,2,4)\n",
        "ax4.imshow(img_back, cmap='gray')\n",
        "ax4.title.set_text('After inverse FFT')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "j1wsj2wt9HIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title face\n",
        "import cv2\n",
        "import face_recognition\n",
        "from simple_facerec import SimpleFacerec\n",
        "\n",
        "img=cv2.imread('modi.png')\n",
        "\n",
        "#rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "cv2.imshow(\"Image\", img)\n",
        "\n",
        "#cv2.imshow(\"Image\", rgb_img)\n",
        "\n",
        "cv2.waitKey(0)\n",
        "\n",
        "\n",
        "#First step for Face recongnition is to encode the image.\n",
        "\n",
        "#encode the imported image and comapre with the other images in the folder \n",
        "\n",
        "\n",
        "img_encoding = face_recognition.face_encoings(img)[0]\n",
        "\n",
        "\n",
        "# Repeat the step for another image\n",
        "\n",
        "\n",
        "img1=cv2.imread('D:/VIT/Fall 22-23/Vision and Image Processing/lab/Frec/images/dhoni.png'  )\n",
        "\n",
        "#rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "cv2.imshow(\"second Image\", img1)\n",
        "\n",
        "#cv2.imshow(\"Image\", rgb_img)\n",
        "\n",
        "\n",
        "#img1_encoding = face_recognition.face_encoings(img1)[0]\n",
        "\n",
        "#cv2.waitKey(0)\n",
        "\n",
        "\n",
        "\n",
        "# Step 3: comparison of images\n",
        "\n",
        "#comapre the face, if both the images are same it will print true.\n",
        "\n",
        "result = face_recognition.compare_faces([img_encoding], img1_encoding) \n",
        "\n",
        "print(\"Result:\", result)\n",
        "\n",
        "\n",
        "\"\"\"step4: encode all the faces in the dataset  (why - through the webcam video streaming)\n",
        "\n",
        "if it find a match in the dataset, it shows the name )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Encode the face from the folder\"\"\"\n",
        "\n",
        "sfr = SimpleFacerec()\n",
        "sfr.load_encoding_images(\"images/\")  # images/ is the name of the folder contains image\n",
        "\n",
        "\n",
        "\"\"\"Step 4: Face recognition in real-time on a webcam\"\"\"\n",
        "\n",
        "# https://pysource.com/wp-content/uploads/2021/08/source-code-face-recognition.zip\n",
        "\n",
        "\"\"\" From the link above download  simple_facerec.py  (keep this .py file in the image dateset folder)\"\"\"\n",
        "\n",
        "\n",
        "#Step5:   Take webcame stream\n",
        "\n",
        "cap = cv2.VideoCapture(2)\n",
        "\n",
        "while True:\n",
        "    ret, frame=cap.read()\n",
        "    \n",
        "    \n",
        " \n",
        "    #Step 5: Face location and face recognition\n",
        "    \n",
        "    \n",
        "#Identify the face passing the frame of the webcam to the function\n",
        "\n",
        "# detect_known_faces(frame)  - it will give name of the person.\n",
        "\n",
        "\n",
        "face_locations, face_names = sfr.detect_known_faces(frame)\n",
        "\n",
        "for face_loc, name in zip(face_locations, face_names):\n",
        "    y1, x2, y2, x1 = face_loc[0], face_loc[1], face_loc[2] \n",
        "\n",
        "\n",
        "#step 6: Show name and rectangle\n",
        "\n",
        "cv2.putText(frame, name, (x1, y1 -10)), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 0, 200), 2)\n",
        "\n",
        "cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 200), 4)\n",
        "\n",
        "cv2.imshow(\"FRAME\", frame)\n",
        "\n",
        "key = cv2.waitKey(1)\n",
        "\n",
        "if key == 27;:\n",
        "    break\n"
      ],
      "metadata": {
        "id": "7X3PmPa99aEZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}